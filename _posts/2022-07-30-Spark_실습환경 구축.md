---
layout: post
title: About Hadoop, Spark, Flow
subtitle: Using pyspark by python
categories: BigData
tags: Hadoop Spark Flow
---

## 설치 프로그램

1. Python(anaconda)
2. java(oracle jdk 11) - Spark 구성 언어
3. Hadoop winutils 2.7.7 - Hadoop 환경 간접 설정
4. apache spark

## 환경 변수 설정

1. PYSPARK_PYTHON
2. JAVA_HOME
3. HADOOP_HOME
4. SPARK_HOME

## Spark 기본 용어

### SparkConf

Spark 설정 옵션 객체, 주로 Spark Context 설정

#### setMaster

Spark가 실행될 위치 설청, local 또는 분산(HDFS) 등을 사용

#### setAppName

스파크에서 작업할 어플리케이션의 이름, 웹 환경(Spark UI)에서 확인이 가능하다

#### SparkContext

- Spark 클러스터와 연결 시켜주는 객체
- Spark의 모든 기능에 접근할 수 있는 시작점
- Spark는 분산 환경에서 동작하기 때문에 Driver Program을 구동시키기 위해서는 SparkContext가 필요하다
- SparkContext는 프로그램당 하나만 만들수 있고, 사용후에는 종료해야 한다

#### SparkContext 작동 과정

1. SparkContext 객체의 내부는 자바로 동작하는 Pyj4의 SparkContext와 소켓을 통해 연결된다
2. Py4j란 Python되어 있는 코드를 Spark에서 구동 가능한 java 형태의 스칼라로 변환
3. RDD를 만들 수 있다.(Spark에서 사용하는 데이터 구조)

### Hadoop

#### HDFS

파일 시스템(분산 저장)

#### Map Reduce

1. 연산 엔진
2. 데이터 집계
3. Spark의 주 기능

#### Yarn

1. 리소스 관리
2. 클러스터 관리

![CPUFlow](https://user-images.githubusercontent.com/77920565/182545861-ea4e3863-20f1-4b68-b9b1-37cb7d7d7f71.png)

### 컴퓨터 Flow

- 컴퓨터 작업 시 HDD/SSD에서 CPU로 데이터가 이동
- 연산에 자주 사용될 수록 위쪽에 저장
- HDD/SSD로 갈수록 용량은 크지만 처리 속도가 현저히 느려지기 때문에 데이터를 어디에 저장할지 잘 판단해야 한다

![Flow](https://user-images.githubusercontent.com/77920565/182546665-69e770db-af1d-46d2-8805-e8748e652308.png)

- RAM에서 처리하기 힘든 크기의 데이터는 HDD/SSD와 연동하여 처리한다
- RAM에서 일부 연산할 데이터를 RAM에 적재, 연산 후 결과를 디스크에 저장한다
- 단, 속도가 현저히 느리다는 단점이 있다

![DataSplit](https://user-images.githubusercontent.com/77920565/182546823-3dc174b7-eb5b-45c4-b7e1-f2b58316fe39.png)

- LEADER에서 FOLLOWER을 관리하고, 데이터를 분산하여 전송
- FOLLOWER에서는 LEADER에서 넘겨준 데이터를 받아 실질적인 연산을 처리한다

### Spark에서의 Cluster

- LEADER역할을 하는 Cluster에서 Dirver Program은 각각의 Worker Node에 연산(Task)을 할당해준다.
- Worker Node(Follower) Cluster에서는 Executor에서 작업을 수행하고 이를 Cache에 저장한다.
- Cluster Manager는 어떤 Worker Node에서 Task를 빠르게 수행할 수 있는지 판단하여 분배하는 역할을 한다.

#### Cluster Toplogy
- 스파크는 MAster - Worker Topology로 구성되어 있다
- 항상 데이터가 여러 곳에 분산되어 있다
- 같은 연산 이라도 여러 노드에 걸쳐서 실행될 수 있다
- 분산된 위치에는 Worker가 존재, Master가 내리는 명령을 수행한다

### Lazy Evaluation

- Task를 정의할 때 연산을 바로 하지 않고, 결과가 필요할 때 연산을 수행한다, 연산 과정을 최적화 한다

### Resilient Distribute Dataset(RDD)

- 탄력적 분산 데이터 세트
- 분산된 노드에 걸쳐서 저장 된다
- 변경이 불가능하다
- 여러 개의 파티션으로 분리 될 수 있다
- 데이터 추상화: 데이터를 여러 클러스터에 저장하지만 하나의 파일에 존재하는 것 처럼 사용한다
- 데이터가 불변하면 문제 발생 시 복원이 쉽다
- RDD는 변환을 거치면 기존의 RDD가 변하는 것이 아닌 변경된 새로운 RDD가 만들어 진다(Immutable): 비순환 그래프

### Data-Parallel 작동 방식(병렬 처리)

1. 빅 데이터를 여러 개로 나눈다
2. 여러 쓰레드에서 각자 task를 수행한다
3. 각각의 결과물을 합친다

### Distributed Data-Parallel 작동 방식(병렬 처리)

1. 더 큰 빅 데이터의 경우 데이터를 나누어 여러 노드로 보낸다
2. 여러 노드에서 독립적으로 task를 수행한다
3. 각 노드의 task 결과물을 합친다

### 분산 처리의 문제

1. 부분 실패 문제
   - 노드 몇 개가 프로그램과 상관 없는 외부적인 요인으로 실패
   - 네트워크 병목현상, 정전, 침수 등 물리적인 원인도 포함된다
2. 속도
   - 많은 네트워크 통신을 필요로 하는 작업의 경우 속도가 저하된다

### Storage Level

#### MEMORY_ONLY
   - MEMORY(RAM)에서만 데이터를 올려 놓기

#### MEMORY_AND_DISK
   - MEMORY, DISK 동시에 데이터를 올려 놓기
   - 메모리에 용량이 부족하면 DISK에 데이터를 올려 놓는다

#### MEMORY_ONLY_SER, MEMORY_AND_DISK_SER
   - SER은 Serialization의 약자, 저장되는 데이터의 용량을 아끼기 위해 직렬화를 수행한다
   - 저장하는 용량은 줄어들지만, 데이터를 읽어올 때 Deserialization이 수행되어야 하기 때문에 데이터를 불러오는 시간이 늘어날 수 있다.

### Partition
   - 데이터를 최대한 균일하게 퍼트린다
   - 쿼리가 같이 되는 데이터를 최대한 옆에 두어 검색 성능을 향상 시킨다
   - Key-Value RDD일 때만 의미가 있다
     - 일반 RDD의 경우 어차피 어떤 데이터를 가져오기 위해서 처음부터 검색해야 한다
   - 하나의 노드는 여러 개의 파티션을 가질 수 있다
   - Hash Partitioning
     - 데이터를 여러 파티션에 균일하게 분배하는 방식, keys를 비교해 비슷한 key는 근접하게 저장한다
     - skew: Hask Partitioning으로 데이터를 분리했을 때 데이터가 극단적으로 몰리는 현상
   - Range Partitioning
     - 순서가 있는 정렬된 파티셔닝
   - 디스크에서 파티션
     - partitionBy() - 주로 이용
       - Transformations: 바로 실행되지 않고 RDD를 생성한다는 약속만 갖는다
       - 파티션 생성 후 persist(), cache()를 실행하지 않을 경우 다음 연산에 불릴 때 마다 반복하게 되어 셔플링이 반복적으로 계속 일어난다

### 메모리에서 파티션
* Repartitions(), coalesce() 둘 다 파티션 개수를 조절하는 함수로 Shuffling을 동반하기 때문에 코스트가 높은 작업이다
 - repartition()
   - 파티션의 크기를 줄이거나 늘리는데 사용된다
 - coalesce()
   - 파티션의 크기를 줄이는데 사용된다
   - 줄이는 작업의 경우 coalesce()가 더 효율적이다
 - map(), flatMap()
   - 키의 변형이 가능하기 때문에 데이터의 파티션이 변경될 여지가 있다
 - mapValues(), flatMapValues()
   - 파티션이 잘 정의 되어 있고, 파티션이 변경되기를 원하지 않을 경우 바람직하다