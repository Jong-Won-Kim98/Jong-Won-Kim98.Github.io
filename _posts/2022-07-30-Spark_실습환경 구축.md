---
layout: post
title: Preparing for environment
subtitle: Using pyspark by python
categories: BigData
tags: Spark pyspark
---

## 설치 프로그램

1. Python(anaconda)
2. java(oracle jdk 11) - Spark 구성 언어
3. Hadoop winutils 2.7.7 - Hadoop 환경 간접 설정
4. apache spark

## 환경 변수 설정

1. PYSPARK_PYTHON
2. JAVA_HOME
3. HADOOP_HOME
4. SPARK_HOME

## Spark 기본 용어

### SparkConf

Spark 설정 옵션 객체, 주로 Spark Context 설정

#### setMaster

Spark가 실행될 위치 설청, local 또는 분산(HDFS) 등을 사용

#### setAppName

스파크에서 작업할 어플리케이션의 이름, 웹 환경(Spark UI)에서 확인이 가능하다

### SparkContext

- Spark 클러스터와 연결 시켜주는 객체
- Spark의 모든 기능에 접근할 수 있는 시작점
- Spark는 분산 환경에서 동작하기 때문에 Driver Program을 구동시키기 위해서는 SparkContext가 필요하다
- SparkContext는 프로그램당 하나만 만들수 있고, 사용후에는 종료해야 한다

### SparkContext 작동 과정

1. SparkContext 객체의 내부는 자바로 동작하는 Pyj4의 SparkContext와 소켓을 통해 연결된다
2. Py4j란 Python되어 있는 코드를 Spark에서 구동 가능한 java 형태의 스칼라로 변환
3. RDD를 만들 수 있다.(Spark에서 사용하는 데이터 구조)

### Hadoop

#### HDFS

파일 시스템(분산 저장)

#### Map Reduce

1. 연산 엔진
2. 데이터 집계
3. Spark의 주 기능

#### Yarn

1. 리소스 관리
2. 클러스터 관리

![CPUFlow](https://user-images.githubusercontent.com/77920565/182545861-ea4e3863-20f1-4b68-b9b1-37cb7d7d7f71.png)

### 컴퓨터 Flow

- 컴퓨터 작업 시 HDD/SSD에서 CPU로 데이터가 이동
- 연산에 자주 사용될 수록 위쪽에 저장
- HDD/SSD로 갈수록 용량은 크지만 처리 속도가 현저히 느려지기 때문에 데이터를 어디에 저장할지 잘 판단해야 한다

![Flow](https://user-images.githubusercontent.com/77920565/182546665-69e770db-af1d-46d2-8805-e8748e652308.png)

- RAM에서 처리하기 힘든 크기의 데이터는 HDD/SSD와 연동하여 처리한다
- RAM에서 일부 연산할 데이터를 RAM에 적재, 연산 후 결과를 디스크에 저장한다
- 단, 속도가 현저히 느리다는 단점이 있다

![DataSplit](https://user-images.githubusercontent.com/77920565/182546823-3dc174b7-eb5b-45c4-b7e1-f2b58316fe39.png)

- LEADER에서 FOLLOWER을 관리하고, 데이터를 분산하여 전송
- FOLLOWER에서는 LEADER에서 넘겨준 데이터를 받아 실질적인 연산을 처리한다

### Spark에서의 Cluster

- LEADER역할을 하는 Cluster에서 Dirver Program은 각각의 Worker Node에 연산(Task)을 할당해준다.
- Worker Node(Follower) Cluster에서는 Executor에서 작업을 수행하고 이를 Cache에 저장한다.
- Cluster Manager는 어떤 Worker Node에서 Task를 빠르게 수행할 수 있는지 판단하여 분배하는 역할을 한다.

### Lazy Evaluation

- Task를 정의할 때 연산을 바로 하지 않고, 결과가 필요할 때 연산을 수행한다, 연산 과정을 최적화 한다

### Resilient Distribute Dataset(RDD)

- 탄력적 분산 데이터 세트
- 분산된 노드에 걸쳐서 저장 된다
- 변경이 불가능하다
- 여러 개의 파티션으로 분리 될 수 있다
- 데이터 추상화: 데이터를 여러 클러스터에 저장하지만 하나의 파일에 존재하는 것 처럼 사용한다
- 데이터가 불변하면 문제 발생 시 복원이 쉽다
- RDD는 변환을 거치면 기존의 RDD가 변하는 것이 아닌 변경된 새로운 RDD가 만들어 진다(Immutable): 비순환 그래프

### Data-Parallel 작동 방식(병렬 처리)

1. 빅 데이터를 여러 개로 나눈다
2. 여러 쓰레드에서 각자 task를 수행한다
3. 각각의 결과물을 합친다

### Distributed Data-Parallel 작동 방식(병렬 처리)

1. 더 큰 빅 데이터의 경우 데이터를 나누어 여러 노드로 보낸다
2. 여러 노드에서 독립적으로 task를 수행한다
3. 각 노드의 task 결과물을 합친다

### 분산 처리의 문제

1. 부분 실패 문제
   - 노드 몇 개가 프로그램과 상관 없는 외부적인 요인으로 실패
   - 네트워크 병목현상, 정전, 침수 등 물리적인 원인도 포함된다
2. 속도
   - 많은 네트워크 통신을 필요로 하는 작업의 경우 속도가 저하된다